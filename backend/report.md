**Data Generation**:
In this simple model we suppose that each bin has a binary signal 0 for empty and 1 for full. These reports can come from QR codes, smart bins, etc. For now se suppose that the signals are all uncorrelated: for each bin a probability of success p is drawn uniformely at random each time and from it a time series of zeros and ones is generated.
**Model training**:
Given these observations we train a NN model in an autoregressive fashion, i.e., we want to classify the state of one bin at time t given the observations of that bin at all the previous times. To do so we can use a simple RNN model, in our case this is composed by 1 LSTM and 2 fully connected layers.
**Predictions**:
After the model is trained the predictions are made by generating a test set in the same way of the train and the predictions are made by sampling from the predicted distribution, i.e. if for a bin the model predicts 0.80 (model confidence that the state of the bin is full is 80%) then the prediction for the bin is a Bernoulli random variable with parameter 0.80. This is usually done in the context of time series classification (in NLP for example) since it is not always true that the best predicted time series is obtain by picking the class with highest confidence at each step (for this reason usually approaches like our or more sofisticated like the beam search are taken).
